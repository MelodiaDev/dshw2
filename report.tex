\documentclass[a4paper,9pt]{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{cmap}
\usepackage{geometry}
\usepackage[colorlinks,linkcolor=blue,anchorcolor=blue,citecolor=green]{hyperref}
\usepackage{indentfirst}
\usepackage[AutoFakeBold={3}]{xeCJK}
\usepackage{titlesec}

\geometry{margin=1in}

\setCJKmainfont{Adobe Song Std}
\setCJKfamilyfont{hei}{Adobe Heiti Std}
\setmainfont{Times New Roman}

\newcommand{\Limit}{\displaystyle \lim_{n \rightarrow \infty}} 
\newcommand{\hei}{\CJKfamily{hei}}

\title{\textbf{数算实习大作业报告}}
\author{\small{倪泽堃(1200012747)\ \ \ 罗翔宇(1200012779)\ \ \ 顾澄(1200012882)}}
\date{\today}

\begin{document}

\maketitle
\section{概况}

\section{分模块介绍}

\subsection{Apriori算法}

\subsection{FP算法}

\subsection{改进算法}
本模块由倪泽堃同学负责编写。FP树和暴力的Apriori算法并没有非常显然的改进思路，因而选取了Apriori算法变种Eclat算法为切入点进行改进。Eclat算法对于每一个频繁项集记录包含它的交易编号，每次作扩展的时候，就求出两个项集的交易编号集合之交，判断其元素个数即可。但是首先的问题是对于mushroom这项数据与支持度K=5\%，最终结果就有几百万项，如果计算过程中直接用vector保存每项的交易编号集合，那么内存消耗极大，一般的4G内存电脑不能承受。因而我们需要寻求其他的方式，比如用一个bitset来记录交易编号集合，每位1/0表示该交易在/不在集合里。这样32个bit压成一个4字节int储存，内存消耗大大减小。每次直接对两个bitset做与运算并调用库函数count获取集合大小。这样最初的改进版本写成，但是对mushroom 5\%这组数据运行时间达到了27.9秒（-O3优化，不算最后排序输出，运行环境为Intel Core i5-2430M CPU @ 2.40GHz$\times$4、Arch Linux 64-bit，下同），实在是有点长，需要大力优化。由于其他两个数据风格不一样，在前4个优化中，就仅仅使用mushroom 5\%这个数据。

\paragraph{优化1：vector改成静态数组}
运用gprof对最初版本进行分析显示，运行时间的大部分消耗在vector的插入上。显然，vector实在是太慢了。因此经过一番努力，我将求解部分的大部分用到vector的地方改用自己实现的静态vector存储，用一个巨大的内存池和一个标明可用空间起点的指针，每次直接计算出需要存储的序列，并将该序列写入内存池中，将指针后移。这样经过改进，所得的优化版本1的性能有很大提升。具体可见下表。
\begin{center}
	\begin{tabular}{ccccccc}
		版本&优化方法&运行时间&bitset内存使用&生成项集数&平均使用&项集废弃率\\\hline
		最初版本&-&27.9&-&-&-\\
		优化版本1&使用静态数组&14.5&5082240280&5002205&1016&24.9\%
	\end{tabular}
\end{center}

\paragraph{优化2：去除bitset中连续0}
显然，使用bitset存储之后，还有可以改进之处：$k$ 越大，频繁 $k$-项集的支持度计数就越小，此时bitset中将有许多的连续0。我们对此作出改进：在32位压成一个int存储的bitset中，将等于0的int从中去除，用二元组记录不为0的元素的下标与值。尽管由一元变成了二元组，作出改进后的优化版本2中内存使用仍然减少了，而且时间效率有极大的上升。具体可见下表。
\begin{center}
	\begin{tabular}{ccccccc}
		版本&优化方法&运行时间&bitset内存使用&生成项集数&平均使用&项集废弃率\\\hline
		优化版本1&使用静态数组&14.5&5082240280&5002205&1016&24.9\%\\
		优化版本2&去除连续0&7.1&3460183168&5002205&692&24.9\%
	\end{tabular}
\end{center}

\paragraph{优化3：重标号、排序}
压缩连续0的效果仍然不够理想。可以想像，其中原因是编号过于分散，存储的数据不够紧凑。因此需要对交易重新排序，使得内容相近的交易处在尽量近的位置。这时，可以发现，将含有最频繁的项的交易排在一起，再将含有第二频繁的项的交易排在一起，以此类推，所得的交易序列相邻项相似度非常高，是比较优的。因此先将项按频繁程度重新标号，将交易排序，然后进行求解。加上该优化所得的优化版本3效率见下表。
\begin{center}
	\begin{tabular}{ccccccc}
		版本&优化方法&运行时间&bitset内存使用&生成项集数&平均使用&项集废弃率\\\hline
		优化版本2&去除连续0&7.1&3460183168&5002205&692&24.9\%\\
		优化版本3&重标号、排序&6.1&2791211776&12782139&218&70.6\%
	\end{tabular}
\end{center}

\paragraph{优化4：频繁序列降序存储}
令人稍有惊讶的是，优化版本3的优化幅度不甚理想。从表中可以很显然地看到，虽然数据存储更加紧凑了，但是该算法多增长出了大量支持度小于给定阈值的候选项集。经过分析可以发现，该算法由序列 $\{a_0,a_1,...,a_{n-1}\}$ 与 $\{a_0,a_1,...,a_{n-2},a_n\}$ 增长出 $\{a_0,a_1,...,a_n\}$, 但是由于 $a_{n-1},a_n$ 比较罕见，增长出的序列支持度可能会剧烈下降。相反，如果从 $\{a_1,...,a_n\}$ 与 $\{a_0,a_2,...,a_n\}$ 增长出目标序列，支持度下降幅度则一般不会很大。因此改用降序存储频繁项集，经测试，所得的优化版本4效率有极大的提升，如下表所示。
\begin{center}
	\begin{tabular}{ccccccc}
		版本&优化方法&运行时间&bitset内存使用&生成项集数&平均使用&项集废弃率\\\hline
		优化版本3&重标号、排序&6.1&2791211776&12782139&218&70.6\%\\
		优化版本4&降序增长&2.0&978700888&3780460&259&0.7\%
	\end{tabular}
\end{center}
在优化版本4中，废弃率已经降低到惊人的程度，数据的存储也很紧凑，运行时间降低到了2秒，而之后的排序就要1.6秒，可以说效率已经相当高了。将其他两组数据也纳入统计，可以对刚才的所有优化做个总结。
\begin{center}
	\begin{tabular}{ccccc}
		版本&优化方法&mushroom 5\%&T10I4D100K 0.1\%&retail 0.1\%\\\hline
		最初版本&-&27.9&-&-\\
		优化版本1&使用静态数组&14.5&16.6&123.5\\
		优化版本2&去除连续0&7.1&3.6&7.5\\
		优化版本3&重标号、排序&6.1&2.2&6.8\\
		优化版本4&降序增长&2.0&2.0&4.4
	\end{tabular}
\end{center}

\paragraph{优化5：预处理频繁2项集} 我们发现，T10I4D100K 0.1\%这组数据答案才27532，但是却花了2.0秒才计算出答案。这是因为计算频繁2项集时，多扩展了许多支持度很低的项集。因而可以使用一个很简单的方法，就是预处理出频繁2项集。优化后的版本5效率如下表所示。
\begin{center}
	\begin{tabular}{ccccc}
		版本&优化方法&mushroom 5\%&T10I4D100K 0.1\%&retail 0.1\%\\\hline
		优化版本4&降序增长&2.0&2.0&4.4\\
		优化版本5&预处理2项集&2.0&0.8&1.0
	\end{tabular}
\end{center}

\paragraph{优化6：部分基数排序} 此时我们的程序已经非常优了。不过如果最后进行排序输出，效率还是比较堪忧的，其中排序就要花费比较长的时间。观察到我们是对序列排序，而每一项并不大。因而在序列长度较长的时候，可以先用基数排序，当每个桶的元素个数小于一定数的时候再用快排排序。经过改进后排序效率有所增加，如下表所示，其中运行时间加上了排序的时间，但不包括输出时间。
\begin{center}
	\begin{tabular}{ccccc}
		版本&优化方法&mushroom 5\%&T10I4D100K 0.1\%&retail 0.1\%\\\hline
		优化版本5&预处理2项集&3.6&0.8&1.0\\
		优化版本6&部分基数排序&3.0&0.8&1.0
	\end{tabular}
\end{center}
值得注意的是，将输出时间加上，对于mushroom 5\%这组数据，程序总共运行时间达到了7s，这说明效率主要瓶颈在输出了。也就是说现在的优化版本6已经是非常优了。因此，可以说优化已经基本完成。

\paragraph{一些思考} 可以发现，最终的这个版本其实和FP树有异曲同工之处。对项按频繁程度排序并对交易重标号、排序的过程和FP树的构建其实是相同的，而降序增长其实跟FP算法从底层向上递归的思想也是一致的，去除了连续0，也就是选取了FP树中一些包含当前频繁项集的节点。但是这个算法的优势在于，FP树中不频繁项出现得很零散，不利于处理，但是该算法将节点进行了压位存储，并且调用内置函数快速统计1出现次数，在这种情况下这个算法比FP算法优很多。但是当FP算法递归到高层频繁节点时，FP算法已经能统计出每个高层节点下有多少个包含当前频繁项集的交易，从而往上递归时直接利用当前计算结果，而本算法增长方式还是Apriori的，必须通过求集合交来获得增长后的支持度，因而在包含高层频繁节点下可能会劣于FP算法，但是另一方面来说，FP算法只进行前缀扩展而不通过两个频繁项集的交，可能会多扩展出废状态来。总体来说，这个改进算法属于FP算法和Apriori（Tidset）算法的结合，但是核心操作仍然在于Tidset算法的集合交。从总体效率上来讲，这个算法比起实现较好的FP算法来说仍然是优的。

\section{心得体会}

\end{document}
